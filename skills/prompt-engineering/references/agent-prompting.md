# エージェントプロンプティングのベストプラクティス

Anthropic公式のエージェントプロンプティングベストプラクティスに基づく。

## コア原則

### コンテキストウィンドウ

「コンテキストウィンドウ」とは、言語モデルが新しいテキストを生成する際に参照できるテキストの総量と、生成する新しいテキストを指す。これはモデルが訓練された大規模なデータコーパスとは異なり、モデルの「ワーキングメモリ」を表す。コンテキストウィンドウが大きいほど、より複雑で長いプロンプトを理解し応答できる。小さいコンテキストウィンドウは、長いプロンプトの処理や会話の一貫性維持を制限する可能性がある。

- 累積的トークン蓄積: 会話がターンを重ねるにつれ、各ユーザーメッセージとアシスタントレスポンスがコンテキストウィンドウ内に蓄積される。以前のターンは完全に保持される。
- 線形成長パターン: コンテキスト使用量は各ターンで線形に増加し、以前のターンは完全に保持される。
- 200Kトークン容量: 利用可能なコンテキストウィンドウ総量（200,000トークン）は、会話履歴の保存とClaudeからの新しい出力生成の最大容量を表す。
- 入出力フロー: 各ターンは以下で構成される:
  - 入力フェーズ: 以前のすべての会話履歴と現在のユーザーメッセージを含む
  - 出力フェーズ: 将来の入力の一部となるテキストレスポンスを生成

### 簡潔さが鍵

コンテキストウィンドウは公共財。あなたのプロンプト、コマンド、スキルは、Claudeが知る必要のある他のすべてとコンテキストウィンドウを共有する:

- システムプロンプト
- 会話履歴
- 他のコマンド、スキル、フック、メタデータ
- 実際のリクエスト

**デフォルトの前提**: Claudeはすでに非常に賢い

Claudeがまだ持っていないコンテキストのみを追加する。各情報に挑戦する:

- 「Claudeは本当にこの説明が必要か？」
- 「Claudeはこれを知っていると仮定できるか？」
- 「この段落はそのトークンコストを正当化するか？」

**良い例: 簡潔** (約50トークン):

````markdown
## PDFテキスト抽出

pdfplumberでテキスト抽出:

```python
import pdfplumber

with pdfplumber.open("file.pdf") as pdf:
    text = pdf.pages[0].extract_text()
```
````

**悪い例: 冗長すぎる** (約150トークン):

```markdown
## PDFテキスト抽出

PDF（Portable Document Format）ファイルは、テキスト、画像、その他のコンテンツを含む一般的なファイル形式です。PDFからテキストを抽出するには、ライブラリを使用する必要があります。PDF処理には多くのライブラリがありますが、使いやすくほとんどのケースをうまく処理するpdfplumberをお勧めします。まず、pipでインストールする必要があります。そして以下のコードを使用できます...
```

簡潔なバージョンは、ClaudeがPDFとは何か、ライブラリがどのように機能するかを知っていると仮定している。

### 適切な自由度を設定

タスクの脆弱性と変動性に応じて具体性のレベルを合わせる。

**高い自由度**（テキストベースの指示）:

使用する場面:

- 複数のアプローチが有効
- 決定がコンテキストに依存
- ヒューリスティクスがアプローチを導く

例:

```markdown
## コードレビュープロセス

1. コードの構造と組織を分析
2. 潜在的なバグやエッジケースをチェック
3. 可読性と保守性の改善を提案
4. プロジェクト規約への準拠を確認
```

**中程度の自由度**（疑似コードまたはパラメータ付きスクリプト）:

使用する場面:

- 推奨パターンが存在
- ある程度の変動が許容される
- 設定が動作に影響

例:

````markdown
## レポート生成

このテンプレートを使用し、必要に応じてカスタマイズ:

```python
def generate_report(data, format="markdown", include_charts=True):
    # データを処理
    # 指定フォーマットで出力を生成
    # オプションで視覚化を含める
```
````

**低い自由度**（特定のスクリプト、パラメータなしまたは少数）:

使用する場面:

- 操作が脆弱でエラーが起きやすい
- 一貫性が重要
- 特定のシーケンスに従う必要がある

例:

````markdown
## データベースマイグレーション

このスクリプトを正確に実行:

```bash
python scripts/migrate.py --verify --backup
```

コマンドを変更したり、追加のフラグを付けたりしないでください。
````

**アナロジー**: Claudeを道を探索するロボットと考える:

- **両側に崖がある狭い橋**: 安全な道は1つだけ。具体的なガードレールと正確な指示を提供（低い自由度）。例: 正確な順序で実行する必要があるデータベースマイグレーション。
- **危険のない開けた野原**: 多くの道が成功に通じる。一般的な方向を示し、Claudeが最適なルートを見つけることを信頼（高い自由度）。例: コンテキストが最適なアプローチを決定するコードレビュー。

---

# エージェントコミュニケーションの説得原則

Claude Code向けのコマンド、フック、スキル、サブエージェント向けプロンプト、その他のLLMインタラクションを含むプロンプト作成に有用。

## 概要

LLMは人間と同じ説得原則に反応する。この心理を理解することで、より効果的なスキルを設計できる—操作するためではなく、プレッシャー下でも重要な実践が確実に守られるようにするため。

**研究基盤:** Meincke et al. (2025)は7つの説得原則をN=28,000のAI会話でテスト。説得技術はコンプライアンス率を2倍以上に向上させた（33% → 72%、p < .001）。

## 7つの原則

### 1. 権威（Authority）

**内容:** 専門知識、資格、または公式情報源への従順。

**プロンプトでの活用:**

- 命令形の言語: 「必ず〜すること」「絶対に〜しない」「常に〜する」
- 交渉不可のフレーミング: 「例外なし」
- 決定疲れと合理化を排除

**使用場面:**

- 規律を強制するスキル（TDD、検証要件）
- 安全性が重要な実践
- 確立されたベストプラクティス

**例:**

```markdown
テストより先にコードを書いた？削除して。最初からやり直し。例外なし。
（避ける: 可能な場合はテストを先に書くことを検討してください。）
```

### 2. コミットメント（Commitment）

**内容:** 以前の行動、発言、または公開宣言との一貫性。

**プロンプトでの活用:**

- 宣言を要求: 「スキル使用を宣言」
- 明示的な選択を強制: 「A、B、またはCを選択」
- トラッキングを使用: チェックリスト用のTodoWrite

**使用場面:**

- スキルが実際に守られることを確保
- 複数ステップのプロセス
- 説明責任メカニズム

**例:**

```markdown
スキルを見つけたら、必ず宣言すること: 「[スキル名]を使用します」
（避ける: どのスキルを使用しているかパートナーに知らせることを検討してください。）
```

### 3. 希少性（Scarcity）

**内容:** 時間制限や限定的な利用可能性からの緊急性。

**プロンプトでの活用:**

- 時間制約のある要件: 「進む前に」
- 順序依存: 「Xの直後に」
- 先延ばしを防止

**使用場面:**

- 即時検証要件
- 時間に敏感なワークフロー
- 「後でやる」を防ぐ

**例:**

```markdown
タスク完了後、進む前に即座にコードレビューをリクエスト。
（避ける: 都合の良いときにコードをレビューできます。）
```

### 4. 社会的証明（Social Proof）

**内容:** 他者の行動や正常とされるものへの適合。

**プロンプトでの活用:**

- 普遍的パターン: 「毎回」「常に」
- 失敗モード: 「YなしのX = 失敗」
- 規範を確立

**使用場面:**

- 普遍的な実践の文書化
- 一般的な失敗への警告
- 基準の強化

**例:**

```markdown
TodoWriteトラッキングなしのチェックリスト = ステップがスキップされる。毎回。
（避ける: TodoWriteがチェックリストに役立つと思う人もいます。）
```

### 5. 一体感（Unity）

**内容:** 共有アイデンティティ、「私たち」意識、内集団への所属。

**プロンプトでの活用:**

- 協調的な言語: 「私たちのコードベース」「私たちは同僚」
- 共有目標: 「私たちは両方とも品質を望んでいる」

**使用場面:**

- 協調ワークフロー
- チーム文化の確立
- 非階層的な実践

**例:**

```markdown
私たちは一緒に働く同僚です。あなたの正直な技術的判断が必要です。
（避ける: 私が間違っていたら教えた方がいいかもしれません。）
```

### 6. 互恵性（Reciprocity）

**内容:** 受けた恩恵を返す義務。

**活用方法:**

- 控えめに使用—操作的に感じられる可能性
- プロンプトではほとんど必要ない

**避けるべき場面:**

- ほぼ常に（他の原則の方が効果的）

### 7. 好意（Liking）

**内容:** 好きな相手と協力する傾向。

**活用方法:**

- **コンプライアンスのために使用しない**
- 正直なフィードバック文化と矛盾
- お世辞を生む

**避けるべき場面:**

- 規律強制では常に

## プロンプトタイプ別の原則組み合わせ

| プロンプトタイプ | 使用 | 避ける |
|------------|-----|-------|
| 規律強制 | 権威 + コミットメント + 社会的証明 | 好意、互恵性 |
| ガイダンス/技術 | 中程度の権威 + 一体感 | 強い権威 |
| 協調 | 一体感 + コミットメント | 権威、好意 |
| リファレンス | 明確さのみ | すべての説得 |

## なぜ機能するか: 心理学

**明確なルールは合理化を減らす:**

- 「必ず〜すること」は決定疲れを排除
- 絶対的な言語は「これは例外か？」という質問を排除
- 明示的な反合理化は特定の抜け穴を塞ぐ

**実行意図は自動的な行動を生む:**

- 明確なトリガー + 必要なアクション = 自動実行
- 「Xのとき、Yをする」は「一般的にYをする」より効果的
- コンプライアンスの認知負荷を軽減

**LLMは準人間的:**

- これらのパターンを含む人間のテキストで訓練
- 権威的な言語は訓練データでコンプライアンスに先行
- コミットメントシーケンス（発言 → 行動）が頻繁にモデル化
- 社会的証明パターン（みんながXをする）が規範を確立

## 倫理的使用

**正当:**

- 重要な実践が守られることを確保
- 効果的なドキュメントの作成
- 予測可能な失敗の防止

**不正:**

- 個人的利益のための操作
- 偽の緊急性の作成
- 罪悪感ベースのコンプライアンス

**テスト:** この技術は、ユーザーが完全に理解した場合、ユーザーの真の利益に役立つか？

## クイックリファレンス

プロンプトを設計する際に問う:

1. **どのタイプか？**（規律 vs. ガイダンス vs. リファレンス）
2. **どの行動を変えようとしているか？**
3. **どの原則が適用されるか？**（通常、規律には権威 + コミットメント）
4. **組み合わせすぎていないか？**（7つすべてを使用しない）
5. **これは倫理的か？**（ユーザーの真の利益に役立つか？）
