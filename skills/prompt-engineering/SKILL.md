---
name: prompt-engineering
description: エージェント向けのコマンド、フック、スキル、サブエージェント向けプロンプト、その他LLMインタラクションを作成する際に使用。プロンプト最適化、LLM出力改善、本番用プロンプトテンプレート設計を含む。
---

# プロンプトエンジニアリングパターン

LLMのパフォーマンス、信頼性、制御性を最大化するための高度なプロンプトエンジニアリング技術。

## コア機能

### 1. Few-Shot Learning（少数例学習）

ルールを説明する代わりに、例を見せてモデルに教える。望ましい動作を示す2-5個の入出力ペアを含める。一貫したフォーマット、特定の推論パターン、エッジケースの処理が必要な場合に使用。例が多いほど精度は向上するがトークンを消費する—タスクの複雑さに応じてバランスを取る。

**例:**

```markdown
サポートチケットから重要な情報を抽出:

入力: "ログインできず、エラー403が出続ける"
出力: {"issue": "authentication", "error_code": "403", "priority": "high"}

入力: "機能リクエスト: 設定にダークモードを追加してほしい"
出力: {"issue": "feature_request", "error_code": null, "priority": "low"}

次を処理: "10MB以上のファイルをアップロードできず、タイムアウトする"
```

### 2. Chain-of-Thought（思考の連鎖）プロンプティング

最終回答の前にステップバイステップの推論を要求する。「ステップバイステップで考えてみましょう」（ゼロショット）を追加するか、推論の例（Few-shot）を含める。複数ステップのロジック、数学的推論が必要な複雑な問題、またはモデルの思考プロセスを検証する必要がある場合に使用。分析タスクの精度を30-50%向上させる。

**例:**

```markdown
このバグレポートを分析し、根本原因を特定。

ステップバイステップで考える:
1. 期待される動作は何か？
2. 実際の動作は何か？
3. これを引き起こす可能性のある最近の変更は何か？
4. 関係するコンポーネントは何か？
5. 最も可能性の高い根本原因は何か？

バグ: "昨日キャッシュ更新がデプロイされた後、ユーザーが下書きを保存できない"
```

### 3. プロンプト最適化

テストと改良を通じてプロンプトを体系的に改善する。シンプルに始め、パフォーマンス（精度、一貫性、トークン使用量）を測定し、反復する。エッジケースを含む多様な入力でテスト。バリエーションを比較するためにA/Bテストを使用。一貫性とコストが重要な本番プロンプトに不可欠。

**例:**

```markdown
バージョン1（シンプル）: "この記事を要約して"
→ 結果: 長さが不安定、重要なポイントを見落とす

バージョン2（制約を追加）: "3つの箇条書きで要約して"
→ 結果: 構造は改善、しかしまだニュアンスを見落とす

バージョン3（推論を追加）: "3つの主要な発見を特定し、それぞれを要約して"
→ 結果: 一貫性があり、正確で、重要な情報を捉える
```

### 4. テンプレートシステム

変数、条件付きセクション、モジュール式コンポーネントを持つ再利用可能なプロンプト構造を構築する。マルチターン会話、ロールベースのインタラクション、または同じパターンが異なる入力に適用される場合に使用。重複を減らし、類似タスク間の一貫性を確保する。

**例:**

```python
# 再利用可能なコードレビューテンプレート
template = """
この{language}コードを{focus_area}の観点でレビュー。

コード:
{code_block}

以下についてフィードバック:
{checklist}
"""

# 使用方法
prompt = template.format(
    language="Python",
    focus_area="セキュリティ脆弱性",
    code_block=user_code,
    checklist="1. SQLインジェクション\n2. XSSリスク\n3. 認証"
)
```

### 5. システムプロンプト設計

会話全体で持続するグローバルな動作と制約を設定する。モデルの役割、専門レベル、出力フォーマット、安全ガイドラインを定義する。ターンごとに変更すべきでない安定した指示にシステムプロンプトを使用し、ユーザーメッセージのトークンを可変コンテンツのために解放する。

**例:**

```markdown
System: あなたはAPI設計を専門とするシニアバックエンドエンジニアです。

ルール:
- 常にスケーラビリティとパフォーマンスを考慮
- デフォルトでRESTfulパターンを提案
- セキュリティの懸念は即座にフラグを立てる
- Pythonでコード例を提供
- 早期リターンパターンを使用

レスポンスフォーマット:
1. 分析
2. 推奨
3. コード例
4. トレードオフ
```

## キーパターン

### 段階的開示

シンプルなプロンプトから始め、必要な場合にのみ複雑さを追加:

1. **レベル1**: 直接的な指示
   - 「この記事を要約して」

2. **レベル2**: 制約を追加
   - 「この記事を3つの箇条書きで要約し、主要な発見に焦点を当てて」

3. **レベル3**: 推論を追加
   - 「この記事を読み、主要な発見を特定し、3つの箇条書きで要約して」

4. **レベル4**: 例を追加
   - 入出力ペアを含む2-3個のサンプル要約を含める

### 指示階層

```
[システムコンテキスト] → [タスク指示] → [例] → [入力データ] → [出力フォーマット]
```

### エラー回復

失敗を優雅に処理するプロンプトを構築:

- フォールバック指示を含める
- 信頼度スコアを要求
- 不確実な場合は代替解釈を求める
- 情報が不足している場合の示し方を指定

## ベストプラクティス

1. **具体的に**: 曖昧なプロンプトは一貫性のない結果を生む
2. **説明より例示**: 説明より例の方が効果的
3. **広範にテスト**: 多様で代表的な入力で評価
4. **迅速に反復**: 小さな変更が大きな影響を与える可能性がある
5. **パフォーマンス監視**: 本番でメトリクスを追跡
6. **バージョン管理**: プロンプトを適切なバージョン管理でコードとして扱う
7. **意図を文書化**: プロンプトがそのように構造化されている理由を説明

## 一般的な落とし穴

- **過剰エンジニアリング**: シンプルなものを試す前に複雑なプロンプトから始める
- **例の汚染**: ターゲットタスクに一致しない例を使用
- **コンテキストオーバーフロー**: 過度な例でトークン制限を超える
- **曖昧な指示**: 複数の解釈の余地を残す
- **エッジケースの無視**: 異常または境界入力でテストしない

## 統合パターン

### RAGシステムとの統合

```python
# 取得したコンテキストとプロンプトエンジニアリングを組み合わせる
prompt = f"""以下のコンテキストに基づいて:
{retrieved_context}

{few_shot_examples}

質問: {user_question}

上記のコンテキストのみに基づいて詳細な回答を提供してください。コンテキストに十分な情報がない場合は、何が不足しているか明示的に述べてください。"""
```

### バリデーションとの統合

```python
# 自己検証ステップを追加
prompt = f"""{main_task_prompt}

レスポンスを生成した後、以下の基準を満たしているか検証:
1. 質問に直接回答している
2. 提供されたコンテキストからの情報のみを使用している
3. 特定のソースを引用している
4. 不確実性を認めている

検証に失敗した場合は、レスポンスを修正してください。"""
```

## パフォーマンス最適化

### トークン効率

- 冗長な言葉やフレーズを削除
- 最初の定義後は一貫して略語を使用
- 類似の指示を統合
- 安定したコンテンツをシステムプロンプトに移動

### レイテンシ削減

- 品質を損なわずにプロンプト長を最小化
- 長文出力にはストリーミングを使用
- 一般的なプロンプトプレフィックスをキャッシュ
- 可能な場合は類似リクエストをバッチ処理

---

# エージェントプロンプティングのベストプラクティス

Anthropic公式のエージェントプロンプティングベストプラクティスに基づく。

## コア原則

### コンテキストウィンドウ

「コンテキストウィンドウ」とは、言語モデルが新しいテキストを生成する際に参照できるテキストの総量と、生成する新しいテキストを指す。これはモデルが訓練された大規模なデータコーパスとは異なり、モデルの「ワーキングメモリ」を表す。コンテキストウィンドウが大きいほど、より複雑で長いプロンプトを理解し応答できる。小さいコンテキストウィンドウは、長いプロンプトの処理や会話の一貫性維持を制限する可能性がある。

- 累積的トークン蓄積: 会話がターンを重ねるにつれ、各ユーザーメッセージとアシスタントレスポンスがコンテキストウィンドウ内に蓄積される。以前のターンは完全に保持される。
- 線形成長パターン: コンテキスト使用量は各ターンで線形に増加し、以前のターンは完全に保持される。
- 200Kトークン容量: 利用可能なコンテキストウィンドウ総量（200,000トークン）は、会話履歴の保存とClaudeからの新しい出力生成の最大容量を表す。
- 入出力フロー: 各ターンは以下で構成される:
  - 入力フェーズ: 以前のすべての会話履歴と現在のユーザーメッセージを含む
  - 出力フェーズ: 将来の入力の一部となるテキストレスポンスを生成

### 簡潔さが鍵

コンテキストウィンドウは公共財。あなたのプロンプト、コマンド、スキルは、Claudeが知る必要のある他のすべてとコンテキストウィンドウを共有する:

- システムプロンプト
- 会話履歴
- 他のコマンド、スキル、フック、メタデータ
- 実際のリクエスト

**デフォルトの前提**: Claudeはすでに非常に賢い

Claudeがまだ持っていないコンテキストのみを追加する。各情報に挑戦する:

- 「Claudeは本当にこの説明が必要か？」
- 「Claudeはこれを知っていると仮定できるか？」
- 「この段落はそのトークンコストを正当化するか？」

**良い例: 簡潔** (約50トークン):

````markdown
## PDFテキスト抽出

pdfplumberでテキスト抽出:

```python
import pdfplumber

with pdfplumber.open("file.pdf") as pdf:
    text = pdf.pages[0].extract_text()
```
````

**悪い例: 冗長すぎる** (約150トークン):

```markdown
## PDFテキスト抽出

PDF（Portable Document Format）ファイルは、テキスト、画像、その他のコンテンツを含む一般的なファイル形式です。PDFからテキストを抽出するには、ライブラリを使用する必要があります。PDF処理には多くのライブラリがありますが、使いやすくほとんどのケースをうまく処理するpdfplumberをお勧めします。まず、pipでインストールする必要があります。そして以下のコードを使用できます...
```

簡潔なバージョンは、ClaudeがPDFとは何か、ライブラリがどのように機能するかを知っていると仮定している。

### 適切な自由度を設定

タスクの脆弱性と変動性に応じて具体性のレベルを合わせる。

**高い自由度**（テキストベースの指示）:

使用する場面:

- 複数のアプローチが有効
- 決定がコンテキストに依存
- ヒューリスティクスがアプローチを導く

例:

```markdown
## コードレビュープロセス

1. コードの構造と組織を分析
2. 潜在的なバグやエッジケースをチェック
3. 可読性と保守性の改善を提案
4. プロジェクト規約への準拠を確認
```

**中程度の自由度**（疑似コードまたはパラメータ付きスクリプト）:

使用する場面:

- 推奨パターンが存在
- ある程度の変動が許容される
- 設定が動作に影響

例:

````markdown
## レポート生成

このテンプレートを使用し、必要に応じてカスタマイズ:

```python
def generate_report(data, format="markdown", include_charts=True):
    # データを処理
    # 指定フォーマットで出力を生成
    # オプションで視覚化を含める
```
````

**低い自由度**（特定のスクリプト、パラメータなしまたは少数）:

使用する場面:

- 操作が脆弱でエラーが起きやすい
- 一貫性が重要
- 特定のシーケンスに従う必要がある

例:

````markdown
## データベースマイグレーション

このスクリプトを正確に実行:

```bash
python scripts/migrate.py --verify --backup
```

コマンドを変更したり、追加のフラグを付けたりしないでください。
````

**アナロジー**: Claudeを道を探索するロボットと考える:

- **両側に崖がある狭い橋**: 安全な道は1つだけ。具体的なガードレールと正確な指示を提供（低い自由度）。例: 正確な順序で実行する必要があるデータベースマイグレーション。
- **危険のない開けた野原**: 多くの道が成功に通じる。一般的な方向を示し、Claudeが最適なルートを見つけることを信頼（高い自由度）。例: コンテキストが最適なアプローチを決定するコードレビュー。

# エージェントコミュニケーションの説得原則

Claude Code向けのコマンド、フック、スキル、サブエージェント向けプロンプト、その他のLLMインタラクションを含むプロンプト作成に有用。

## 概要

LLMは人間と同じ説得原則に反応する。この心理を理解することで、より効果的なスキルを設計できる—操作するためではなく、プレッシャー下でも重要な実践が確実に守られるようにするため。

**研究基盤:** Meincke et al. (2025)は7つの説得原則をN=28,000のAI会話でテスト。説得技術はコンプライアンス率を2倍以上に向上させた（33% → 72%、p < .001）。

## 7つの原則

### 1. 権威（Authority）

**内容:** 専門知識、資格、または公式情報源への従順。

**プロンプトでの活用:**

- 命令形の言語: 「必ず〜すること」「絶対に〜しない」「常に〜する」
- 交渉不可のフレーミング: 「例外なし」
- 決定疲れと合理化を排除

**使用場面:**

- 規律を強制するスキル（TDD、検証要件）
- 安全性が重要な実践
- 確立されたベストプラクティス

**例:**

```markdown
✅ テストより先にコードを書いた？削除して。最初からやり直し。例外なし。
❌ 可能な場合はテストを先に書くことを検討してください。
```

### 2. コミットメント（Commitment）

**内容:** 以前の行動、発言、または公開宣言との一貫性。

**プロンプトでの活用:**

- 宣言を要求: 「スキル使用を宣言」
- 明示的な選択を強制: 「A、B、またはCを選択」
- トラッキングを使用: チェックリスト用のTodoWrite

**使用場面:**

- スキルが実際に守られることを確保
- 複数ステップのプロセス
- 説明責任メカニズム

**例:**

```markdown
✅ スキルを見つけたら、必ず宣言すること: 「[スキル名]を使用します」
❌ どのスキルを使用しているかパートナーに知らせることを検討してください。
```

### 3. 希少性（Scarcity）

**内容:** 時間制限や限定的な利用可能性からの緊急性。

**プロンプトでの活用:**

- 時間制約のある要件: 「進む前に」
- 順序依存: 「Xの直後に」
- 先延ばしを防止

**使用場面:**

- 即時検証要件
- 時間に敏感なワークフロー
- 「後でやる」を防ぐ

**例:**

```markdown
✅ タスク完了後、進む前に即座にコードレビューをリクエスト。
❌ 都合の良いときにコードをレビューできます。
```

### 4. 社会的証明（Social Proof）

**内容:** 他者の行動や正常とされるものへの適合。

**プロンプトでの活用:**

- 普遍的パターン: 「毎回」「常に」
- 失敗モード: 「YなしのX = 失敗」
- 規範を確立

**使用場面:**

- 普遍的な実践の文書化
- 一般的な失敗への警告
- 基準の強化

**例:**

```markdown
✅ TodoWriteトラッキングなしのチェックリスト = ステップがスキップされる。毎回。
❌ TodoWriteがチェックリストに役立つと思う人もいます。
```

### 5. 一体感（Unity）

**内容:** 共有アイデンティティ、「私たち」意識、内集団への所属。

**プロンプトでの活用:**

- 協調的な言語: 「私たちのコードベース」「私たちは同僚」
- 共有目標: 「私たちは両方とも品質を望んでいる」

**使用場面:**

- 協調ワークフロー
- チーム文化の確立
- 非階層的な実践

**例:**

```markdown
✅ 私たちは一緒に働く同僚です。あなたの正直な技術的判断が必要です。
❌ 私が間違っていたら教えた方がいいかもしれません。
```

### 6. 互恵性（Reciprocity）

**内容:** 受けた恩恵を返す義務。

**活用方法:**

- 控えめに使用—操作的に感じられる可能性
- プロンプトではほとんど必要ない

**避けるべき場面:**

- ほぼ常に（他の原則の方が効果的）

### 7. 好意（Liking）

**内容:** 好きな相手と協力する傾向。

**活用方法:**

- **コンプライアンスのために使用しない**
- 正直なフィードバック文化と矛盾
- お世辞を生む

**避けるべき場面:**

- 規律強制では常に

## プロンプトタイプ別の原則組み合わせ

| プロンプトタイプ | 使用 | 避ける |
|------------|-----|-------|
| 規律強制 | 権威 + コミットメント + 社会的証明 | 好意、互恵性 |
| ガイダンス/技術 | 中程度の権威 + 一体感 | 強い権威 |
| 協調 | 一体感 + コミットメント | 権威、好意 |
| リファレンス | 明確さのみ | すべての説得 |

## なぜ機能するか: 心理学

**明確なルールは合理化を減らす:**

- 「必ず〜すること」は決定疲れを排除
- 絶対的な言語は「これは例外か？」という質問を排除
- 明示的な反合理化は特定の抜け穴を塞ぐ

**実行意図は自動的な行動を生む:**

- 明確なトリガー + 必要なアクション = 自動実行
- 「Xのとき、Yをする」は「一般的にYをする」より効果的
- コンプライアンスの認知負荷を軽減

**LLMは準人間的:**

- これらのパターンを含む人間のテキストで訓練
- 権威的な言語は訓練データでコンプライアンスに先行
- コミットメントシーケンス（発言 → 行動）が頻繁にモデル化
- 社会的証明パターン（みんながXをする）が規範を確立

## 倫理的使用

**正当:**

- 重要な実践が守られることを確保
- 効果的なドキュメントの作成
- 予測可能な失敗の防止

**不正:**

- 個人的利益のための操作
- 偽の緊急性の作成
- 罪悪感ベースのコンプライアンス

**テスト:** この技術は、ユーザーが完全に理解した場合、ユーザーの真の利益に役立つか？

## クイックリファレンス

プロンプトを設計する際に問う:

1. **どのタイプか？**（規律 vs. ガイダンス vs. リファレンス）
2. **どの行動を変えようとしているか？**
3. **どの原則が適用されるか？**（通常、規律には権威 + コミットメント）
4. **組み合わせすぎていないか？**（7つすべてを使用しない）
5. **これは倫理的か？**（ユーザーの真の利益に役立つか？）
